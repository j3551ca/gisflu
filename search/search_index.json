{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"gisflu","text":"<p>Access the GISAID Flu database using Python. Inspired by GISAIDR, which is an R package for accessing the EpiCoV, EpiRSV and EpiPox database of GISAID.</p>"},{"location":"#install","title":"install","text":"<pre><code># use pip\npip install gisflu\n# use pdm\npdm add gisflu\n</code></pre>"},{"location":"#login","title":"login","text":"<pre><code>import gisflu\n\n# Log in with provided username and password\ngisflu.login(\"myusername\", \"mypassword\")\n\n# Log in using environment variables\ngisflu.login()\n</code></pre>"},{"location":"#search","title":"search","text":"<pre><code>cred = gisflu.login()\ngisflu.search(cred, type=[\"A\"], HA=[\"3\"], NA=[\"2\"],\n    collectDateFrom=\"2020-01-01\", recordLimit=10)\n</code></pre>"},{"location":"#download","title":"download","text":"<pre><code>cred = gisflu.login()\nisolateIds = [\"EPI_ISL_19185107\", \"EPI_ISL_19151100\"]\ngisflu.download(cred, isolateIds, downloadType=\"protein\", segments=[\"HA\", \"NA\"],\n    filename=\"records.fasta\")\n</code></pre>"},{"location":"dev/","title":"\u57fa\u672c\u89c4\u5219","text":"<ul> <li>sid: session id, \u5728\u4e00\u6b21\u4f1a\u8bdd\u4e2d\u4fdd\u6301\u4e0d\u53d8</li> <li>wid: window id\uff0c\u5e73\u94fa\u7a97\u53e3\u5171\u4eab\u540c\u4e00\u4e2a wid\uff0c\u5f39\u51fa\u7684\u4e0a\u5c42\u7a97\u53e3\uff08\u5982\u4e0b\u8f7d\uff09\u4f7f\u7528\u4e0d\u540c\u7684 wid</li> <li>pid: page id\uff0c\u9875\u9762 id\uff0c\u66f4\u6362\u68c0\u7d22\u6761\u4ef6\u4f1a\u53d8\u5316</li> <li>cid: component id\uff0c\u7ec4\u4ef6 id\uff0c\u8bb8\u591a\u51fd\u6570\u9700\u8981\u4f20\u5165 cid</li> <li>ceid: component event id\uff0c\u4f5c\u4e3a\u8bf7\u6c42\u53c2\u6570\u4f7f\u7528</li> <li>ts: time stamp</li> </ul> <p>GISAID \u83b7\u53d6\u53c2\u6570\u4f9d\u8d56 POST \u6216 GET \u8bf7\u6c42\u3002\u5e38\u5c06\u51fd\u6570\u547d\u4ee4\u8fde\u63a5\u4e3a pipeline\uff0c\u8f6c\u5316\u4e3a\u8bf7\u6c42\u53c2\u6570\u53d1\u9001\u7ed9\u670d\u52a1\u5668\uff0c\u5728\u54cd\u5e94\u4e2d\u5305\u542b\u76ee\u7684\u9875\u9762\u7684 pid\uff0c\u6216\u9875\u9762\u7684 HTML</p> <p>\u83b7\u53d6\u6570\u636e\u5c55\u793a\u5728 result page \u7684<code>GetData</code>\uff0c\u7cfb\u7edf\u9650\u5236\u4e00\u6b21\u6700\u591a\u8bbf\u95ee 27 \u6761\u6570\u636e\uff0c\u8d85\u51fa\u8fd9\u4e2a\u6570\u5b57\u7684\u9700\u8981\u5206 batch \u83b7\u53d6</p>"},{"location":"dev/#pid","title":"\u52a8\u6001 pid \u6848\u4f8b","text":"<p>\u5206\u6790 browse page \u5230 result page \u7684\u6d41\u7a0b\uff0c\u53d1\u73b0\u4f1a\u8c03\u7528<code>search, GetData, GoBack</code>\u4e09\u4e2a\u547d\u4ee4\uff0c\u5176\u4e2d\u5728\u4e24\u6b21\u68c0\u7d22\u4e2d\uff0cbrowse page \u7684 pid \u4fdd\u6301\u4e0d\u53d8\uff0c\u800c result page \u7684 pid \u4f1a\u53d8\u5316</p> <pre><code>{\"queue\":[{\"wid\":\"wid_sf13al_7vm3\",\"pid\":\"pid_sf13al_8ttf\",\"cid\":\"c_sf13al_14b\",\"cmd\":\"search\",\"params\":{},\"equiv\":null}]}\n{\"queue\":[{\"wid\":\"wid_sf13al_7vm3\",\"pid\":\"pid_sf13al_95tz\",\"cid\":\"c_sf13al_14h\",\"cmd\":\"GetData\",\"params\":{}}]}\n{\"queue\":[{\"wid\":\"wid_sf13al_7vm3\",\"pid\":\"pid_sf13al_95tz\",\"cid\":\"c_sf13al_14j\",\"cmd\":\"GoBack\",\"params\":{},\"equiv\":null}]}\n\n{\"queue\":[{\"wid\":\"wid_sf13al_7vm3\",\"pid\":\"pid_sf13al_8ttf\",\"cid\":\"c_sf13al_14b\",\"cmd\":\"search\",\"params\":{},\"equiv\":null}]}\n{\"queue\":[{\"wid\":\"wid_sf13al_7vm3\",\"pid\":\"pid_sf13al_9646\",\"cid\":\"c_sf13al_14h\",\"cmd\":\"GetData\",\"params\":{}}]}\n{\"queue\":[{\"wid\":\"wid_sf13al_7vm3\",\"pid\":\"pid_sf13al_9646\",\"cid\":\"c_sf13al_14j\",\"cmd\":\"GoBack\",\"params\":{},\"equiv\":null}]}\n</code></pre> <p>\u5206\u6790 result page \u5230 download page \u7684\u6d41\u7a0b\uff08\u4ee5\u9009\u62e9 protein \u4e3a\u4f8b\uff09\uff0c\u53d1\u73b0\u4f1a\u8c03\u7528<code>Download, ShowProteins, Cancel</code>\u4e09\u4e2a\u547d\u4ee4\uff0c\u5176\u4e2d\u5728\u4e24\u6b21\u5524\u8d77\u4e0b\u8f7d\u9762\u677f\u4e2d\uff0cresult page \u7684 pid \u4fdd\u6301\u4e0d\u53d8\uff0c\u800c download page \u7684 pid \u4f1a\u53d8\u5316\u3002\u6ce8\u610f\uff0c\u4e24\u6b21\u6253\u5f00 download page \u65f6\uff0c\u5bf9\u5e94\u7684\u4e0a\u5c42 wid \u4e5f\u53d8\u4e86\uff0c\u800c cid \u548c ceid \u4e0d\u53d8</p> <pre><code>{\"wid\":\"wid_sf13al_7vm3\",\"pid\":\"pid_sf13al_9cxb\",\"cid\":\"c_sf13al_14j\",\"cmd\":\"Download\",\"params\":{},\"equiv\":null}\n{\"wid\":\"wid_sf13al_9cxt\",\"pid\":\"pid_sf13al_9cxu\",\"cid\":\"c_sf13al_14m\",\"cmd\":\"ShowProteins\",\"params\":{\"ceid\":\"ce_sf13al_dm\"},\"equiv\":null}\n{\"queue\":[{\"wid\":\"wid_sf13al_9cxt\",\"pid\":\"pid_sf13al_9cxu\",\"cid\":\"c_sf13al_14m\",\"cmd\":\"Cancel\",\"params\":{},\"equiv\":null}]}\n\n{\"wid\":\"wid_sf13al_7vm3\",\"pid\":\"pid_sf13al_9cxb\",\"cid\":\"c_sf13al_14j\",\"cmd\":\"Download\",\"params\":{},\"equiv\":null}\n{\"wid\":\"wid_sf13al_9d1x\",\"pid\":\"pid_sf13al_9d1y\",\"cid\":\"c_sf13al_14m\",\"cmd\":\"ShowProteins\",\"params\":{\"ceid\":\"ce_sf13al_dm\"},\"equiv\":null}\n{\"queue\":[{\"wid\":\"wid_sf13al_9d1x\",\"pid\":\"pid_sf13al_9d1y\",\"cid\":\"c_sf13al_14m\",\"cmd\":\"Cancel\",\"params\":{},\"equiv\":null}]}\n</code></pre>"},{"location":"dev/#_2","title":"\u51fd\u6570\u7ec6\u8282","text":""},{"location":"dev/#gisflulogin","title":"gisflu.login()","text":"<ul> <li>\u767b\u5f55 GISAID</li> <li>\u8fdb\u5165 browse page \u5e76\u89e3\u6790\u5143\u7d20 id</li> <li>\u4e0d\u505a\u4efb\u4f55\u53c2\u6570\u7b5b\u9009\uff0c\u8fdb\u5165 result page \u5e76\u89e3\u6790\u5143\u7d20 id\u3002\u6b64\u65f6 result page \u5305\u542b\u6240\u6709 records\uff0c\u9009\u62e9\u4e00\u4e2a\u4e34\u65f6\u8bb0\u5f55\uff0c\u83b7\u53d6 download page \u7684 id</li> <li>\u8fdb\u5165 download page \u5e76\u89e3\u6790\u5143\u7d20 id</li> <li>\u8fd4\u56de browse page\u3002\u5982\u679c\u6ca1\u6709\u8be5\u6b65\u9aa4\uff0c\u540e\u7eed\u6784\u9020\u7684\u8bf7\u6c42\u4f1a\u8fd4\u56de\u7a7a\u503c</li> </ul>"},{"location":"dev/#gisflusearch","title":"gisflu.search()","text":"<ul> <li>\u5728 browse page \u4f20\u5165\u53c2\u6570\u641c\u7d22</li> <li>\u8fdb\u5165 result page\uff0c\u83b7\u53d6 records \u7684 json\uff0c\u8f6c\u4e3a pandas \u683c\u5f0f</li> <li>\u8fd4\u56de browse page\u3002\u5982\u679c\u6ca1\u6709\u8be5\u6b65\u9aa4\uff0c\u540e\u7eed\u6784\u9020\u7684\u8bf7\u6c42\u4f1a\u8fd4\u56de\u7a7a\u503c</li> </ul>"},{"location":"dev/#gisfludownload","title":"gisflu.download()","text":"<ul> <li>\u5728<code>gisflu.login()</code>\u767b\u5f55\u540e\u5373\u53ef\u4f7f\u7528\uff0c\u4e0d\u9700\u8981\u9884\u5148\u8c03\u7528<code>gisflu.search()</code></li> <li>\u6839\u636e<code>isolateIds</code>\u4e0b\u8f7d</li> <li>\u4e0d\u505a\u4efb\u4f55\u53c2\u6570\u7b5b\u9009\uff0c\u8fdb\u5165 result page \u5e76\u89e3\u6790\u5143\u7d20 id</li> <li>\u52fe\u9009\u9700\u8981\u7684<code>isolates</code></li> <li>\u8fdb\u5165 download page\uff0c\u9009\u62e9\u4e0b\u8f7d<code>metadata, protein, dna</code></li> <li>\u8bbe\u7f6e fasta header</li> <li>\u83b7\u53d6\u4e0b\u8f7d\u94fe\u63a5</li> <li>\u4fdd\u5b58\u5230\u672c\u5730</li> </ul>"},{"location":"dev/#_3","title":"\u9875\u9762\u4ecb\u7ecd","text":"<p>\u8bbf\u95ee<code>https://platform.epicov.org/epi3/frontend</code>\u540e\uff0c\u9996\u5148\u8fdb\u5165 login page</p> <p></p> <p>\u767b\u5f55\u540e\u8fdb\u5165 first page\uff0c\u9ed8\u8ba4\u4e3a EpiCoV \u6570\u636e\u5e93</p> <p></p> <p>\u901a\u8fc7\u5bfc\u822a\u680f\u5207\u6362\u5230 Flu \u6570\u636e\u5e93\uff0c\u8fdb\u5165 home page</p> <p></p> <p>\u70b9\u51fb<code>Search</code>\u8fdb\u5165 browse page</p> <p></p> <p>\u8bbe\u7f6e filter \u6761\u4ef6\uff0c\u70b9\u51fb<code>Search</code>\u8fdb\u5165 result page</p> <p></p> <p>\u52fe\u9009\u9700\u8981\u4e0b\u8f7d\u7684 records\uff0c\u70b9\u51fb<code>Download</code>\u8fdb\u5165 download page\u3002\u8be5\u9875\u9762\u901a\u8fc7 Overlap Window \u5448\u73b0</p> <p></p>"},{"location":"dev/#_4","title":"\u5f85\u529e","text":"<ul> <li>\u91cd\u6784<code>buildDownloadCommand</code>\uff0c\u5e94\u7528\u5230<code>gisflu.login()</code>\u548c<code>gisflu.login()</code></li> </ul>"},{"location":"reference/","title":"Reference","text":""},{"location":"reference/#gisflu.login.login","title":"<code>login(username=None, password=None)</code>","text":"<p>Login the GISAID Flu database, parse elements ids and store them in a credentials object.</p> <p>Parameters:</p> Name Type Description Default <code>username</code> <code>str</code> <p>The username to log in with. If not provided, it will be fetched from the environment variable \"GISAID_USERNAME\".</p> <code>None</code> <code>password</code> <code>str</code> <p>The password to log in with. If not provided, it will be fetched from the environment variable \"GISAID_PASSWORD\".</p> <code>None</code> Return <p>credentials</p> Example <pre><code># Log in with provided username and password\ngisflu.login(\"myusername\", \"mypassword\")\n\n# Log in using environment variables\ngisflu.login()\n</code></pre> Source code in <code>src/gisflu/login.py</code> <pre><code>def login(username: str | None = None, password: str | None = None) -&gt; credentials:\n    \"\"\"\n    Login the GISAID Flu database, parse elements ids and store them in a credentials object.\n\n    Args:\n        username (str, optional): The username to log in with. If not provided, it will be fetched from the environment variable \"GISAID_USERNAME\".\n        password (str, optional): The password to log in with. If not provided, it will be fetched from the environment variable \"GISAID_PASSWORD\".\n\n    Return:\n        credentials\n\n    Example:\n        ```\n        # Log in with provided username and password\n        gisflu.login(\"myusername\", \"mypassword\")\n\n        # Log in using environment variables\n        gisflu.login()\n        ```\n    \"\"\"\n\n    cred = credentials()\n\n    # get username and password\n    if username is None or password is None:\n        logger.debug(\n            \"Username and password not provided, fetching from environment variables\"\n        )\n\n        username = os.getenv(\"GISAID_USERNAME\")\n        password = os.getenv(\"GISAID_PASSWORD\")\n\n        assert (\n            username is not None\n        ), 'Please set the environment variable \"GISAID_USERNAME\"'\n        assert (\n            password is not None\n        ), 'Please set the environment variable \"GISAID_PASSWORD\"'\n\n    password_md5 = hashlib.md5(password.encode()).hexdigest()\n\n    # fetch sessionId first\n    res = httpGet(cred.url, headers=cred.headers)\n    cred.sessionId = re.search(r'name=\"sid\" value=\\'(.+?)\\'', res.text).group(1)\n    logger.debug(f\"Get sessionId: {cred.sessionId}\")\n\n    # then get login page, to get more ids\n    res = httpGet(f\"{cred.url}?sid={cred.sessionId}\", headers=cred.headers)\n    loginPageText = res.text\n    cred.windowId = re.search(r'sys\\[\"WID\"\\] = \"(.+?)\";', loginPageText).group(1)\n    cred.loginPage[\"pid\"] = re.search(r'sys\\[\"PID\"\\] = \"(.+?)\";', loginPageText).group(\n        1\n    )\n    cred.loginPage[\"loginCompId\"] = re.search(\n        r\"sys.getC\\(\\'(.+?)\\'\\).call\\(\\'doLogin\\'\", loginPageText\n    ).group(1)\n\n    # login by command pipeline\n    cmdPipe = [\n        buildCommand(\n            CompId=cred.loginPage[\"loginCompId\"],\n            cmd=\"doLogin\",\n            params={\"login\": username, \"hash\": password_md5},\n        )\n    ]\n\n    body = buildRequestBody(\n        cred.sessionId, cred.windowId, cred.loginPage[\"pid\"], cmdPipe, mode=\"ajax\"\n    )\n\n    res = httpPost(cred.url, data=body, headers=cred.headers)\n    assert re.search(\"cms_page\", res.text), \"Username or password wrong!\"\n    logger.debug(\"username and password validated!\")\n\n    # first page after login\n    logger.debug(\"Go to first page...\")\n    res = httpGet(f\"{cred.url}?sid={cred.sessionId}\", headers=cred.headers)\n    firstPageText = res.text\n    cred.firstPage[\"pid\"] = re.search(r'sys\\[\"PID\"\\] = \"(.+?)\";', firstPageText).group(\n        1\n    )\n    cred.firstPage[\"dbSwitchCompId\"] = re.search(\n        r\"sys.call\\(\\'(.+?)\\',\\'Go\\'\", firstPageText\n    ).group(1)\n\n    # fetch flu home page id by command pipeline\n    logger.debug(\"Go to flu homepage...\")\n    cmdPipe = [\n        buildCommand(\n            CompId=cred.firstPage[\"dbSwitchCompId\"], cmd=\"Go\", params={\"page\": \"epi3\"}\n        )\n    ]\n\n    body = buildRequestBody(\n        cred.sessionId, cred.windowId, cred.firstPage[\"pid\"], cmdPipe\n    )\n\n    res = httpPost(cred.url, data=body, headers=cred.headers)\n    homePagePid = re.search(r\"sys.goPage\\(\\'(.+?)\\'\\)\", res.text).group(1)\n    cred.homePage[\"pid\"] = homePagePid\n\n    # go to flu home page\n    res = httpGet(\n        f\"{cred.url}?sid={cred.sessionId}&amp;pid={homePagePid}\", headers=cred.headers\n    )\n    homePageText = res.text\n\n    ################## browse page ####################\n    logger.debug(\"Parse browse page...\")\n\n    # fetch browse(search) page id\n    cred.homePage[\"browseCompId\"] = re.search(\n        r\"class=\\\"sys-actionbar-action-ni\\\" onclick=\\\"sys.getC\\(\\'(.+?)\\'\\)\",\n        homePageText,\n    ).group(1)\n\n    cmdPipe = [buildCommand(CompId=cred.homePage[\"browseCompId\"], cmd=\"Browse\")]\n\n    body = buildRequestBody(\n        cred.sessionId, cred.windowId, cred.homePage[\"pid\"], cmdPipe\n    )\n\n    res = httpPost(cred.url, data=body, headers=cred.headers)\n\n    browsePagePid = re.search(r\"sys.goPage\\(\\'(.+?)\\'\\)\", res.text).group(1)\n    cred.browsePage[\"pid\"] = browsePagePid\n\n    # go to browse page\n    res = httpGet(\n        f\"{cred.url}?sid={cred.sessionId}&amp;pid={browsePagePid}\", headers=cred.headers\n    )\n    browsePageText = res.text\n\n    cred.browsePage[\"browseFormCompId\"] = re.search(\n        r\"sys\\.createComponent\\(\\'(c_\\w+?)\\',\\'IsolateBrowseFormComponent\\'\",\n        browsePageText,\n    ).group(1)\n\n    cred.browsePage[\"searchButtonCompId\"] = re.search(\n        r\"sys\\.createComponent\\(\\'(c_\\w+?)\\',\\'IsolateSearchButtonsComponent\\'\",\n        browsePageText,\n    ).group(1)\n\n    # fetch browse component event id\n    browseItemText = re.findall(r\"createFI\\(.+?function\", browsePageText)\n\n    browseItemDict = {}\n    for s in browseItemText:\n        ident = re.search(r\"Widget\\',\\'(.+?)\\',function\", s).group(1)\n        ceid = re.search(r\"createFI\\(\\'(.+?)\\',\", s).group(1)\n        browseItemDict[ident] = ceid\n\n    cred.browseParamsCeid[\"type\"] = browseItemDict[\"isl_type\"]\n    cred.browseParamsCeid[\"HA\"] = browseItemDict[\"isl_subtype_h\"]\n    cred.browseParamsCeid[\"NA\"] = browseItemDict[\"isl_subtype_n\"]\n    cred.browseParamsCeid[\"lineage\"] = browseItemDict[\"isl_lineage\"]\n    cred.browseParamsCeid[\"host\"] = browseItemDict[\"isl_host\"]\n    cred.browseParamsCeid[\"location\"] = browseItemDict[\"isl_location\"]\n    cred.browseParamsCeid[\"collectDateFrom\"] = browseItemDict[\"isl_collect_date_from\"]\n    cred.browseParamsCeid[\"collectDateTo\"] = browseItemDict[\"isl_collect_date_to\"]\n\n    ################## result page ####################\n    logger.debug(\"Parse result page...\")\n\n    # fetch result page id\n    cmdPipe = [buildCommand(CompId=cred.browsePage[\"searchButtonCompId\"], cmd=\"search\")]\n    body = buildRequestBody(\n        cred.sessionId, cred.windowId, cred.browsePage[\"pid\"], cmdPipe\n    )\n    res = httpPost(cred.url, data=body, headers=cred.headers)\n    resultPagePid = re.search(r\"sys.goPage\\(\\'(.+?)\\'\\)\", res.text).group(1)\n    cred.resultPage[\"pid\"] = resultPagePid\n\n    # go to result page\n    res = httpGet(\n        f\"{cred.url}?sid={cred.sessionId}&amp;pid={resultPagePid}\", headers=cred.headers\n    )\n    resultPageText = res.text\n    cred.resultPage[\"resultCompId\"] = re.search(\n        r\"sys\\.createComponent\\(\\'(c_\\w+?)\\',\\'IsolateResultListComponent\\'\",\n        resultPageText,\n    ).group(1)\n    cred.resultPage[\"downloadCompId\"] = re.search(\n        r\"sys\\.createComponent\\(\\'(c_\\w+?)\\',\\'IsolateDownloadButtonComponent\\'\",\n        resultPageText,\n    ).group(1)\n\n    # parse result table header\n    tableHeaderText = re.findall(r\"new Object\\(\\{\\'label.+?cid\", resultPageText)\n\n    for s in tableHeaderText:\n        label = re.search(r\"label\\':\\'([\\w ]+?)\\'\", s).group(1)\n        key = re.search(r\"key\\':\\'(\\w+?)\\'\", s).group(1)\n        cred.resultHeaderDict[key] = label\n\n    ################## download page ####################\n    logger.debug(\"Parse download page...\")\n\n    # get a temp record\n    cmdPipe = [\n        buildCommand(\n            CompId=cred.resultPage[\"resultCompId\"],\n            cmd=\"SetPaginating\",\n            params={\"start_index\": 0, \"rows_per_page\": 27},\n        ),\n        buildCommand(CompId=cred.resultPage[\"resultCompId\"], cmd=\"GetData\"),\n    ]\n\n    body = buildRequestBody(\n        cred.sessionId, cred.windowId, cred.resultPage[\"pid\"], cmdPipe\n    )\n    res = httpPost(cred.url, data=body, headers=cred.headers)\n\n    tempRecordId = res.json()[\"records\"][0][\"b\"]\n\n    # select this temp record\n    cmdPipe = [\n        buildCommand(\n            CompId=cred.resultPage[\"resultCompId\"],\n            cmd=\"ChangeValue\",\n            params={\"row_id\": tempRecordId, \"col_name\": \"c\", \"value\": True},\n        ),\n        buildCommand(CompId=cred.resultPage[\"downloadCompId\"], cmd=\"Download\"),\n    ]\n\n    body = buildRequestBody(\n        cred.sessionId, cred.windowId, cred.resultPage[\"pid\"], cmdPipe\n    )\n\n    res = httpPost(cred.url, data=body, headers=cred.headers)\n\n    cred.downloadWindowId, cred.downloadPage[\"pid\"] = re.search(\n        r\"sys.openOverlay\\(\\'(\\w+?)\\',\\'(\\w+?)\\'\", res.text\n    ).group(1, 2)\n\n    # go to download overlay page\n    res = httpGet(\n        f'{cred.url}?sid={cred.sessionId}&amp;pid={cred.downloadPage[\"pid\"]}',\n        headers=cred.headers,\n    )\n    downloadPageText = res.text\n\n    cred.downloadPage[\"resultDownloadCompId\"] = re.search(\n        r\"sys\\.createComponent\\(\\'(c_\\w+?)\\',\\'IsolateResultDownloadComponent\\'\",\n        downloadPageText,\n    ).group(1)\n\n    # fetch download item ceid\n    downloadItemText = re.findall(r\"createFI\\(.+?function\", downloadPageText)\n\n    downloadItemDict = {}\n    for s in downloadItemText:\n        ident = re.search(r\"Widget\\',\\'(.+?)\\',function\", s).group(1)\n        ceid = re.search(r\"createFI\\(\\'(.+?)\\',\", s).group(1)\n        downloadItemDict[ident] = ceid\n\n    cred.downloadParamsCeid[\"downloadFormat\"] = downloadItemDict[\"format\"]\n    cred.downloadParamsCeid[\"downloadConfirm\"] = downloadItemDict[\"download\"]\n\n    # fetch protein segment ceid\n\n    cmdPipe = [\n        buildCommand(\n            CompId=cred.downloadPage[\"resultDownloadCompId\"],\n            cmd=\"setTarget\",\n            params={\n                \"cvalue\": \"proteins\",\n                \"ceid\": cred.downloadParamsCeid[\"downloadFormat\"],\n            },\n            equiv=f'ST{cred.downloadParamsCeid[\"downloadFormat\"]}',\n        ),\n        buildCommand(\n            CompId=cred.downloadPage[\"resultDownloadCompId\"],\n            cmd=\"ChangeValue\",\n            params={\n                \"cvalue\": \"proteins\",\n                \"ceid\": cred.downloadParamsCeid[\"downloadFormat\"],\n            },\n            equiv=f'CV{cred.downloadParamsCeid[\"downloadFormat\"]}',\n        ),\n        buildCommand(\n            CompId=cred.downloadPage[\"resultDownloadCompId\"],\n            cmd=\"ShowProteins\",\n            params={\"ceid\": cred.downloadParamsCeid[\"downloadFormat\"]},\n        ),\n    ]\n\n    body = buildRequestBody(\n        cred.sessionId, cred.downloadWindowId, cred.downloadPage[\"pid\"], cmdPipe\n    )\n\n    res = httpPost(cred.url, data=body, headers=cred.headers)\n\n    downloadProteinText = res.text\n\n    cred.downloadParamsCeid[\"proteinSegment\"] = re.search(\n        r\"createFI\\(\\'(\\w+?)\\',\\'CheckboxWidget\\',\\'proteins\\'\", downloadProteinText\n    ).group(1)\n\n    # fetch dna segment ceid\n    cmdPipe = [\n        buildCommand(\n            CompId=cred.downloadPage[\"resultDownloadCompId\"],\n            cmd=\"setTarget\",\n            params={\n                \"cvalue\": \"dna\",\n                \"ceid\": cred.downloadParamsCeid[\"downloadFormat\"],\n            },\n            equiv=f'ST{cred.downloadParamsCeid[\"downloadFormat\"]}',\n        ),\n        buildCommand(\n            CompId=cred.downloadPage[\"resultDownloadCompId\"],\n            cmd=\"ChangeValue\",\n            params={\n                \"cvalue\": \"dna\",\n                \"ceid\": cred.downloadParamsCeid[\"downloadFormat\"],\n            },\n            equiv=f'CV{cred.downloadParamsCeid[\"downloadFormat\"]}',\n        ),\n        buildCommand(\n            CompId=cred.downloadPage[\"resultDownloadCompId\"],\n            cmd=\"ShowProteins\",\n            params={\"ceid\": cred.downloadParamsCeid[\"downloadFormat\"]},\n        ),\n    ]\n\n    body = buildRequestBody(\n        cred.sessionId, cred.downloadWindowId, cred.downloadPage[\"pid\"], cmdPipe\n    )\n\n    res = httpPost(cred.url, data=body, headers=cred.headers)\n\n    downloadDNAText = res.text\n\n    cred.downloadParamsCeid[\"dnaSegment\"] = re.search(\n        r\"createFI\\(\\'(\\w+?)\\',\\'CheckboxWidget\\',\\'dna\\'\", downloadDNAText\n    ).group(1)\n\n    cred.downloadParamsCeid[\"fastaHeader\"] = re.search(\n        r\"createFI\\(\\'(\\w+?)\\',\\'EntryWidget\\',\\'header\\'\", downloadDNAText\n    ).group(1)\n\n    ################## return browse page ####################\n    downloadToResultPage(cred)\n    resultToBrowsePage(cred)\n    logger.debug(f\"{username} logged!\")\n\n    return cred\n</code></pre>"},{"location":"reference/#gisflu.browse.search","title":"<code>search(cred, type=None, HA=None, NA=None, host=None, collectDateFrom=None, collectDateTo=None, recordLimit=50)</code>","text":"<p>Search for records in the GISAID Flu database based on specified criteria.</p> <p>Parameters:</p> Name Type Description Default <code>cred</code> <code>credentials</code> <p>The credentials object containing session information.</p> required <code>type</code> <code>List[str]</code> <p>A list of virus types to filter the search results. Defaults to None.</p> <code>None</code> <code>HA</code> <code>List[str]</code> <p>A list of hemagglutinin (HA) subtypes to filter the search results. Defaults to None.</p> <code>None</code> <code>NA</code> <code>List[str]</code> <p>A list of neuraminidase (NA) subtypes to filter the search results. Defaults to None.</p> <code>None</code> <code>host</code> <code>List[str]</code> <p>A list of host species to filter the search results. Defaults to None.</p> <code>None</code> <code>collectDateFrom</code> <code>str</code> <p>The starting date for the collection date filter. Defaults to None.</p> <code>None</code> <code>collectDateTo</code> <code>str</code> <p>The ending date for the collection date filter. Defaults to None.</p> <code>None</code> <code>recordLimit</code> <code>int</code> <p>The maximum number of records to return. Defaults to 50.</p> <code>50</code> Return <p>pd.DataFrame: A DataFrame containing the search results.</p> Example <pre><code>cred = gisflu.login()\ngisflu.search(cred, type=[\"A\"], HA=[\"3\"], NA=[\"2\"],\n    collectDateFrom=\"2020-01-01\", recordLimit=10)\n</code></pre> Source code in <code>src/gisflu/browse.py</code> <pre><code>def search(\n    cred: credentials,\n    type: List[str] | None = None,\n    HA: List[str] | None = None,\n    NA: List[str] | None = None,\n    host: List[str] | None = None,\n    collectDateFrom: str | None = None,\n    collectDateTo: str | None = None,\n    recordLimit: int = 50,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Search for records in the GISAID Flu database based on specified criteria.\n\n    Args:\n        cred (credentials): The credentials object containing session information.\n        type (List[str], optional): A list of virus types to filter the search results. Defaults to None.\n        HA (List[str], optional): A list of hemagglutinin (HA) subtypes to filter the search results. Defaults to None.\n        NA (List[str], optional): A list of neuraminidase (NA) subtypes to filter the search results. Defaults to None.\n        host (List[str], optional): A list of host species to filter the search results. Defaults to None.\n        collectDateFrom (str, optional): The starting date for the collection date filter. Defaults to None.\n        collectDateTo (str, optional): The ending date for the collection date filter. Defaults to None.\n        recordLimit (int, optional): The maximum number of records to return. Defaults to 50.\n\n    Return:\n        pd.DataFrame: A DataFrame containing the search results.\n\n    Example:\n        ```\n        cred = gisflu.login()\n        gisflu.search(cred, type=[\"A\"], HA=[\"3\"], NA=[\"2\"],\n            collectDateFrom=\"2020-01-01\", recordLimit=10)\n        ```\n    \"\"\"\n\n    # search by command pipeline\n    cmdPipe = []\n    if type:\n        cmdPipe += buildBrowseCommand(cred, \"type\", type)\n    if HA:\n        cmdPipe += buildBrowseCommand(cred, \"HA\", HA)\n    if NA:\n        cmdPipe += buildBrowseCommand(cred, \"NA\", NA)\n    if host:\n        cmdPipe += buildBrowseCommand(cred, \"host\", host)\n    if collectDateFrom:\n        cmdPipe += buildBrowseCommand(cred, \"collectDateFrom\", collectDateFrom)\n    if collectDateTo:\n        cmdPipe += buildBrowseCommand(cred, \"collectDateTo\", collectDateTo)\n\n    body = buildRequestBody(\n        cred.sessionId, cred.windowId, cred.browsePage[\"pid\"], cmdPipe\n    )\n\n    res = httpPost(cred.url, data=body, headers=cred.headers)\n\n    # records count in the browse page\n    preResultText = res.text\n\n    recordCount, recordSeqCount = [\n        int(i.replace(\",\", \"\"))\n        for i in re.search(\n            r\"Total: ([\\d,]+) viruses \\(([\\d,]+) sequences\\)\", preResultText\n        ).group(1, 2)\n    ]\n\n    logger.info(f\"{recordCount} records, {recordSeqCount} seqs found\")\n\n    # refresh result page id\n    cmdPipe = [buildCommand(CompId=cred.browsePage[\"searchButtonCompId\"], cmd=\"search\")]\n    body = buildRequestBody(\n        cred.sessionId, cred.windowId, cred.browsePage[\"pid\"], cmdPipe\n    )\n    res = httpPost(cred.url, data=body, headers=cred.headers)\n    resultPagePid = re.search(r\"sys.goPage\\(\\'(.+?)\\'\\)\", res.text).group(1)\n    cred.resultPage[\"pid\"] = resultPagePid\n\n    logger.debug(\"Parse result page...\")\n    # go to result page\n    res = httpGet(\n        f\"{cred.url}?sid={cred.sessionId}&amp;pid={resultPagePid}\", headers=cred.headers\n    )\n    resultPageText = res.text\n    cred.resultPage[\"resultCompId\"] = re.search(\n        r\"sys\\.createComponent\\(\\'(c_\\w+?)\\',\\'IsolateResultListComponent\\'\",\n        resultPageText,\n    ).group(1)\n\n    logger.debug(\"Fetch result records...\")\n    # fetch records\n    if recordCount &gt; 0:\n        resultJson = []\n\n        batches = buildBatch(0, min(recordCount, recordLimit) - 1, batchSize=27)\n        for batch in tqdm(batches):\n            cmdPipe = [\n                buildCommand(\n                    CompId=cred.resultPage[\"resultCompId\"],\n                    cmd=\"SetPaginating\",\n                    params={\n                        \"start_index\": batch[\"start\"],\n                        \"rows_per_page\": batch[\"count\"],\n                    },\n                ),\n                buildCommand(CompId=cred.resultPage[\"resultCompId\"], cmd=\"GetData\"),\n            ]\n\n            body = buildRequestBody(\n                cred.sessionId, cred.windowId, cred.resultPage[\"pid\"], cmdPipe\n            )\n            res = httpPost(cred.url, data=body, headers=cred.headers)\n\n            resultJson += res.json()[\"records\"]\n\n        # records dataframe\n        reslutDF = pd.DataFrame(resultJson)\n\n        reslutDF = reslutDF.drop(\n            [s for s in reslutDF.columns if s not in cred.resultHeaderDict.keys()],\n            axis=1,\n        )\n\n        reslutDF = reslutDF.rename(columns=cred.resultHeaderDict)\n\n        reslutDF = reslutDF.drop([\"__toggle__\", \"edit\", \"HE\", \"P3\"], axis=1)\n\n        for col in [\"Name\", \"PB2\", \"PB1\", \"PA\", \"HA\", \"NP\", \"NA\", \"MP\", \"NS\"]:\n            reslutDF[col] = reslutDF[col].str.replace(\n                r\"^.+?&gt;(.+?)&lt;/.+$\", r\"\\1\", regex=True\n            )\n    else:\n        reslutDF = pd.DataFrame()\n\n    resultToBrowsePage(cred)\n\n    nrow = reslutDF.shape[0]\n    logger.debug(f\"Search completed: return {nrow} rows\")\n\n    return reslutDF\n</code></pre>"},{"location":"reference/#gisflu.download.download","title":"<code>download(cred, isolateIds, downloadType='protein', segments=['HA', 'NA'], filename=None)</code>","text":"<p>Downloads records for the given isolate IDs.</p> <p>Parameters:</p> Name Type Description Default <code>cred</code> <code>object</code> <p>The credentials object.</p> required <code>isolateIds</code> <code>list</code> <p>List of isolate IDs to download data for.</p> required <code>downloadType</code> <code>str</code> <p>The type of data to download. Defaults to \"protein\".</p> <code>'protein'</code> <code>segments</code> <code>list</code> <p>List of segments to download. Defaults to [\"HA\", \"NA\"].</p> <code>['HA', 'NA']</code> <code>filename</code> <code>str</code> <p>The name of the file to save the downloaded data. If not provided, a default filename will be generated.</p> <code>None</code> Return <p>None</p> Example <pre><code>cred = gisflu.login()\nisolateIds = [\"EPI_ISL_19185107\", \"EPI_ISL_19151100\"]\ngisflu.download(cred, isolateIds, downloadType=\"protein\", segments=[\"HA\", \"NA\"],\n    filename=\"records.fasta\")\n</code></pre> Source code in <code>src/gisflu/download.py</code> <pre><code>def download(\n    cred: credentials,\n    isolateIds: List[str],\n    downloadType: str = \"protein\",\n    segments: List[str] = [\"HA\", \"NA\"],\n    filename: str | None = None,\n) -&gt; None:\n    \"\"\"\n    Downloads records for the given isolate IDs.\n\n    Args:\n        cred (object): The credentials object.\n        isolateIds (list): List of isolate IDs to download data for.\n        downloadType (str, optional): The type of data to download. Defaults to \"protein\".\n        segments (list, optional): List of segments to download. Defaults to [\"HA\", \"NA\"].\n        filename (str, optional): The name of the file to save the downloaded data. If not provided, a default filename will be generated.\n\n    Return:\n        None\n\n    Example:\n        ```\n        cred = gisflu.login()\n        isolateIds = [\"EPI_ISL_19185107\", \"EPI_ISL_19151100\"]\n        gisflu.download(cred, isolateIds, downloadType=\"protein\", segments=[\"HA\", \"NA\"],\n            filename=\"records.fasta\")\n        ```\n    \"\"\"\n\n    assert all(\n        id.startswith(\"EPI_ISL_\") for id in isolateIds\n    ), 'isolateId must start with \"EPI_ISL_\"'\n\n    assert downloadType in [\n        \"metadata\",\n        \"protein\",\n        \"dna\",\n    ], \"downloadType must be metadata|protein|dna\"\n\n    segmentCheck = [\n        \"NP\",\n        \"P3\",\n        \"HA\",\n        \"M1\",\n        \"M2\",\n        \"BM2\",\n        \"CM2\",\n        \"M\",\n        \"NA\",\n        \"NB\",\n        \"NS1\",\n        \"NEP\",\n        \"NS2\",\n        \"PA\",\n        \"PA-X\",\n        \"PB1-F2\",\n        \"PB1\",\n        \"HE\",\n        \"PB2\",\n    ]\n\n    unknownSegments = [segment for segment in segments if segment not in segmentCheck]\n    unknownSegmentStr = \", \".join(unknownSegments)\n    assert len(unknownSegments) == 0, f\"Unknown segment(s): {unknownSegmentStr}\"\n\n    logger.debug(\"Go to result page...\")\n    # fetch result page id\n    cmdPipe = [buildCommand(CompId=cred.browsePage[\"searchButtonCompId\"], cmd=\"search\")]\n    body = buildRequestBody(\n        cred.sessionId, cred.windowId, cred.browsePage[\"pid\"], cmdPipe\n    )\n    res = httpPost(cred.url, data=body, headers=cred.headers)\n    resultPagePid = re.search(r\"sys.goPage\\(\\'(.+?)\\'\\)\", res.text).group(1)\n    cred.resultPage[\"pid\"] = resultPagePid\n\n    # go to result page\n    res = httpGet(\n        f\"{cred.url}?sid={cred.sessionId}&amp;pid={resultPagePid}\", headers=cred.headers\n    )\n\n    # select records, get download page id\n    cmdPipe = [\n        buildCommand(\n            CompId=cred.resultPage[\"resultCompId\"],\n            cmd=\"ChangeValue\",\n            params={\n                \"row_id\": acc.replace(\"EPI_ISL_\", \"\"),\n                \"col_name\": \"c\",\n                \"value\": True,\n            },\n        )\n        for acc in isolateIds\n    ]\n    cmdPipe += [buildCommand(CompId=cred.resultPage[\"downloadCompId\"], cmd=\"Download\")]\n\n    body = buildRequestBody(\n        cred.sessionId, cred.windowId, cred.resultPage[\"pid\"], cmdPipe\n    )\n\n    res = httpPost(cred.url, data=body, headers=cred.headers)\n\n    cred.downloadWindowId, cred.downloadPage[\"pid\"] = re.search(\n        r\"sys.openOverlay\\(\\'(\\w+?)\\',\\'(\\w+?)\\'\", res.text\n    ).group(1, 2)\n\n    logger.debug(\"Go to download page...\")\n    # go to download overlay page\n    res = httpGet(\n        f'{cred.url}?sid={cred.sessionId}&amp;pid={cred.downloadPage[\"pid\"]}',\n        headers=cred.headers,\n    )\n    resultDownloadCompId = cred.downloadPage[\"resultDownloadCompId\"]\n\n    logger.debug(\"Set download params...\")\n    if downloadType == \"metadata\":\n        cmdPipe = [\n            buildCommand(CompId=resultDownloadCompId, cmd=\"download\"),\n        ]\n\n        body = buildRequestBody(\n            cred.sessionId, cred.downloadWindowId, cred.downloadPage[\"pid\"], cmdPipe\n        )\n\n        res = httpPost(cred.url, data=body, headers=cred.headers)\n\n        api = re.search(r\"sys\\.downloadFile\\(\\\\\\\"(.+?)\\\\\\\"\", res.text).group(1)\n    elif downloadType in [\"protein\", \"dna\"]:\n        if downloadType == \"protein\":\n            typeCvalue = \"proteins\"\n            downloadSegmentCeid = cred.downloadParamsCeid[\"proteinSegment\"]\n            faHeader = \"Protein Accession no.|Gene name|Isolate name|Isolate ID|Type@Collection date\"\n        else:\n            typeCvalue = \"dna\"\n            downloadSegmentCeid = cred.downloadParamsCeid[\"dnaSegment\"]\n            faHeader = (\n                \"DNA Accession no.|Segment|Isolate name|Isolate ID|Type@Collection date\"\n            )\n\n        resultDownloadCompId = cred.downloadPage[\"resultDownloadCompId\"]\n        downloadFormatCeid = cred.downloadParamsCeid[\"downloadFormat\"]\n        fastaHeaderCeid = cred.downloadParamsCeid[\"fastaHeader\"]\n\n        cmdPipe = [\n            # select protein|dna\n            buildCommand(\n                CompId=resultDownloadCompId,\n                cmd=\"setTarget\",\n                params={\n                    \"cvalue\": typeCvalue,\n                    \"ceid\": downloadFormatCeid,\n                },\n                equiv=f\"ST{downloadFormatCeid}\",\n            ),\n            buildCommand(\n                CompId=resultDownloadCompId,\n                cmd=\"ChangeValue\",\n                params={\n                    \"cvalue\": typeCvalue,\n                    \"ceid\": downloadFormatCeid,\n                },\n                equiv=f\"CV{downloadFormatCeid}\",\n            ),\n            buildCommand(\n                CompId=resultDownloadCompId,\n                cmd=\"ShowProteins\",\n                params={\"ceid\": downloadFormatCeid},\n            ),\n            # check segment\n            buildCommand(\n                CompId=resultDownloadCompId,\n                cmd=\"setTarget\",\n                params={\"cvalue\": segments, \"ceid\": downloadSegmentCeid},\n                equiv=f\"ST{downloadSegmentCeid}\",\n            ),\n            buildCommand(\n                CompId=resultDownloadCompId,\n                cmd=\"ChangeValue\",\n                params={\"cvalue\": segments, \"ceid\": downloadSegmentCeid},\n                equiv=f\"CV{downloadSegmentCeid}\",\n            ),\n            buildCommand(\n                CompId=resultDownloadCompId,\n                cmd=\"SelChange\",\n                params={\"ceid\": downloadSegmentCeid},\n            ),\n            # set fasta header\n            buildCommand(\n                CompId=resultDownloadCompId,\n                cmd=\"setTarget\",\n                params={\"cvalue\": faHeader, \"ceid\": fastaHeaderCeid},\n                equiv=f\"ST{fastaHeaderCeid}\",\n            ),\n            buildCommand(\n                CompId=resultDownloadCompId,\n                cmd=\"ChangeValue\",\n                params={\"cvalue\": faHeader, \"ceid\": fastaHeaderCeid},\n                equiv=f\"CV{fastaHeaderCeid}\",\n            ),\n            buildCommand(\n                CompId=resultDownloadCompId,\n                cmd=\"fillExampleCopied\",\n                params={\"ceid\": fastaHeaderCeid},\n            ),\n            # download\n            buildCommand(CompId=resultDownloadCompId, cmd=\"download\"),\n        ]\n\n        body = buildRequestBody(\n            cred.sessionId, cred.downloadWindowId, cred.downloadPage[\"pid\"], cmdPipe\n        )\n\n        res = httpPost(cred.url, data=body, headers=cred.headers)\n\n        api = re.search(r\"sys\\.downloadFile\\(\\\\\\\"(.+?)\\\\\\\"\", res.text).group(1)\n\n    # download\n    logger.debug(\"Downloading...\")\n    now = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n    count = len(isolateIds)\n    if filename is None:\n        if downloadType == \"metadata\":\n            extension = \"xls\"\n        elif downloadType in [\"protein\", \"dna\"]:\n            extension = \"fasta\"\n        filename = f\"gisflu-{downloadType}-{count}records-{now}.{extension}\"\n\n    downloadLink = \"https://\" + urllib.parse.urlparse(cred.url).hostname + api\n    res = httpGet(downloadLink, headers=cred.headers)\n\n    with open(filename, \"wb\") as f:\n        f.write(res.content)\n\n    downloadToResultPage(cred)\n    resultToBrowsePage(cred)\n\n    return None\n</code></pre>"}]}